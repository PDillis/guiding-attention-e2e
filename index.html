<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="Guiding Attention in End-to-End Driving Models"/>
  <meta property="og:description" content=""/>
  <meta property="og:url" content="https://blog.diegoporres.com/guiding-attention-e2e/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/images/guidingatt_banner.jpg" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:site" content="@PDillis">
  <meta name="twitter:title" content="Diego Porres">
  <meta name="twitter:description" content="Guatemalan ðŸ‡¬ðŸ‡¹ physicist, now Ph.D. student @CVC_UAB, researching autonomous driving.">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/guidingatt_banner.jpg">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="autonomous driving, end-to-end driving, attention">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Guiding Attention in End-to-End Driving Models</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Guiding Attention in End-to-End Driving Models</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=Xuv3WuIAAAAJ&hl=en&authuser=1" target="_blank">Diego Porres</a>,</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?hl=en&authuser=1&user=_2mQDJEAAAAJ" target="_blank">Yi Xiao</a>,</span>
                  <span class="author-block">
                    <a href="https://scholar.google.com/citations?hl=en&authuser=1&user=byJeaV0AAAAJ" target="_blank">Gabriel Villalonga</a>,</span>
                    <span class="author-block">
                      <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&user=Um9rfMwAAAAJ" target="_blank">Alexandre Levy</a>,</span>
                      <span class="author-block">
                        <a href="https://scholar.google.com/citations?hl=en&authuser=1&user=3LYW1zMAAAAJ" target="_blank">Antonio M. LÃ³pez</a></span>
                        </div>
                    </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Computer Vision Center<br>Intelligent Vehicles Symposium (IV) 2024</span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2405.00242" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/PDillis/guiding-attention-e2e" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (soon!)</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2405.00242" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%">
        <!-- Your video here -->
        <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Vision-based end-to-end driving models trained by imitation learning can lead to affordable solutions for autonomous driving. However, training these well-performing models usually requires a huge amount of data, while still lacking explicit and intuitive activation maps to reveal the inner workings of these models while driving. In this paper, we study how to guide the attention of these models to improve their driving quality and obtain more intuitive activation maps by adding a loss term during training using salient semantic maps. In contrast to previous work, <strong>our method does not require these salient semantic maps to be available during testing time</strong>, as well as removing the need to modify the model's architecture to which it is applied. We perform tests using perfect and noisy salient semantic maps with encouraging results in both, the latter of which is inspired by possible errors encountered with real data. Using CIL++ as a representative state-of-the-art model and the CARLA simulator with its standard benchmarks, we conduct experiments that show the effectiveness of our method in training better autonomous driving models, especially when data and computational resources are scarce.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<details>
  <summary><strong>I have keys but no doors. I have space but no room. You can enter but canâ€™t leave. What am I?</strong></summary>
  A keyboard.
</details>


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Low Data Regime Experiments</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <!-- Your image here -->
        <img src="static/images/LowDataPlots_DrivingHours.png" alt="Driving results of the models trained with and without the Attention Loss while increasing the amount of training data."/>
        <h2 class="subtitle has-text-centered">
          Driving results of the models trained with and without the Attention Loss while increasing the amount of training data. Training data was collected in <code>Town01</code> and models were evaluated in <code>Town02</code> in CARLA, using new weather conditions.
        </h2>
      </div>
      <div class="item">
        <!-- Your image here -->
        <img src="static/images/LowDataPlots_Weathers.png" alt="Driving results of the models trained with and without the Attention Loss while increasing the number of weather types in the training data (2 hours of data per weather)."/>
        <h2 class="subtitle has-text-centered">
          Driving results of the models trained with and without the Attention Loss while increasing the number of weather types in the training data (2 hours of data per weather). Training data was collected in <code>Town01</code> and models were evaluated in <code>Town02</code> in CARLA, using new weather conditions.
        </h2>
      </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Table carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">High Data Regime Experiments</h2>
      <p>lkajs</p>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">        
        <table>
          <caption>
            Using the <em>synthetic attention masks</em> as different types of input. Soft Mask (SM) appends the mask as a fourth channel to the input RGB image. Hard Mask (HM) does an element-wise multiplication with the RGB channels.
          </caption>
          <thead>
            <tr>
              <th scope="col"></th>
              <th scope="col"><strong>SRâ†‘</strong></th>
              <th scope="col"><strong>DSâ†‘</strong></th>
              <th scope="col"><strong>RCâ†‘</strong></th>
              <th scope="col"><strong>ISâ†‘</strong></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <th scope="row">CIL++</th>
              <td>41.33Â±8.08</td>
              <td>60.45Â±4.6</td>
              <td>73.03Â±4.18</td>
              <td>0.77Â±0.03</td>
            </tr>
            <tr>
              <th scope="row">w/SM</th>
              <td>42.00Â±7.21</td>
              <td>59.29Â±5.49</td>
              <td>70.12Â±4.32</td>
              <td>0.78Â±0.02</td>
            </tr>
            <tr>
              <th scope="row">  w/HM</th>
              <td>66.00Â±9.17</td>
              <td>77.34Â±6.93</td>
              <td>84.32Â±5.83</td>
              <td>0.87Â±0.04</td>
            </tr>
          </tbody>
          <tfoot>
            <tr>
              <th scope="row">  w/Att. Loss</th>
              <td>79.33Â±13.01</td>
              <td>85.67Â±7.84</td>
              <td>91.13Â±6.21</td>
              <td>0.92Â±0.05</td>
            </tr>
          </tfoot>
        </table>

      </div>
      <div class="item">
        <table>
          <caption>
            We now test the effects of errors when predicting the <em>synthetic attention masks</em> to the Soft and Hard Mask paradigms during training and validation. For comparison, we train a model with noisy masks using the Attention Loss, but note that for our case, we do not need to predict these during validation. 
          </caption>
          <thead>
            <tr>
              <th scope="col"></th>
              <th scope="col"><strong>SRâ†‘</strong></th>
              <th scope="col"><strong>DSâ†‘</strong></th>
              <th scope="col"><strong>RCâ†‘</strong></th>
              <th scope="col"><strong>ISâ†‘</strong></th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <th scope="row">CIL++</th>
              <td>41.33Â±8.08</td>
              <td>60.45Â±4.6</td>
              <td>73.03Â±4.18</td>
              <td>0.77Â±0.03</td>
            </tr>
            <tr>
              <th scope="row">w/SM (Noisy Pred. Masks)</th>
              <td>35.33Â±7.02</td>
              <td>56.38Â±1.32</td>
              <td>68.38Â±0.58</td>
              <td>0.77Â±0.01</td>
            </tr>
            <tr>
              <th scope="row">  w/HM (Noisy Pred. Masks)</th>
              <td>66.00Â±7.21</td>
              <td>76.36Â±3.72</td>
              <td>83.46Â±4.48</td>
              <td>0.87Â±0.01</td>
            </tr>
          </tbody>
          <tfoot>
            <tr>
              <th scope="row">  w/Att. Loss (Noisy Masks)</th>
              <td>71.33Â±6.11</td>
              <td>80.36Â±6.88</td>
              <td>89.46Â±3.97</td>
              <td>0.87Â±0.05</td>
            </tr>
          </tfoot>
        </table>
      </div>
  </div>
</div>
</div>
</section>
<!-- End table carousel -->


<!-- Youtube video -->
<!-- <section class="hero is-small is-light"> -->
  <!-- <div class="hero-body"> -->
    <!-- <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2> -->
      <!-- <div class="columns is-centered has-text-centered"> -->
        <!-- <div class="column is-four-fifths"> -->
          
          <!-- <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe> -->
          <!-- </div> -->
        <!-- </div> -->
      <!-- </div> -->
    <!-- </div> -->
  <!-- </div> -->
<!-- </section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video carousel -->






<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/IEEEIV2024_GuidingAttentionPoster.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code >
        @article{porres2024guidingattention,
          title={Guiding Attention in End-to-End Driving Models},
          author={Porres, Diego and Xiao, Yi and Villalonga, Gabriel and Levy, Alexandre and LÃ³pez, Antonio M.},
          booktitle={Proceedings of the IEEE Intelligent Vehicles Symposium (IV) 2024},
          year={2024}
        }
      </code></pre>
    </div>
</section>
<!--End BibTex citation -->

<!--Acknowledgements-->
<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
    <h2 class="title">Acknowledgements</h2>
    <div class="content">
      <p>
        This research is supported by project TED2021-132802BI00 funded by MCIN/AEI/10.13039/501100011033 and the European Union NextGenerationEU/PRTR. Antonio M. Lopez acknowledges the financial support to his general research activities given by ICREA under the ICREA Academia Program. Antonio and Gabriel thank the synergies, in terms of research ideas, arising from the project PID2020-115734RB-C21 funded by MCIN/AEI/10.13039/501100011033. The authors acknowledge the support of the Generalitat de Catalunya CERCA Program and its ACCIO agency to CVCâ€™s general activities.
      </p>
    </div>
  </div>
</section>


<!--End Acknowledgements-->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from theÂ <a href="https://nerfies.github.io" target="_blank">Nerfies</a>Â project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
